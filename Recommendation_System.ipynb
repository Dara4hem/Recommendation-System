{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNq/QkHLivmS3IbppI1G1yJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dara4hem/Recommendation-System/blob/main/Recommendation_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install and Load Dataset"
      ],
      "metadata": {
        "id": "1oXdQIX-uLss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Example: Load MovieLens dataset\n",
        "url = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        "!wget -nc $url\n",
        "!unzip -n ml-latest-small.zip\n",
        "\n",
        "ratings = pd.read_csv('ml-latest-small/ratings.csv')\n",
        "train_data, test_data = train_test_split(ratings, test_size=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCP2cjm_4dfi",
        "outputId": "4b0a024b-704a-4ce4-92f0-4fd6f33042f2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘ml-latest-small.zip’ already there; not retrieving.\n",
            "\n",
            "Archive:  ml-latest-small.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Dataset and DataLoader"
      ],
      "metadata": {
        "id": "r1ZUxS-B4gF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RatingsDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.users = torch.tensor(data['userId'].values)\n",
        "        self.items = torch.tensor(data['movieId'].values)\n",
        "        self.ratings = torch.tensor(data['rating'].values, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ratings)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.users[idx], self.items[idx], self.ratings[idx]\n",
        "\n",
        "train_dataset = RatingsDataset(train_data)\n",
        "test_dataset = RatingsDataset(test_data)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "FfHYrB9e4ho6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determine the Number of Users and Items"
      ],
      "metadata": {
        "id": "snM6rkYB4j7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the number of users and items\n",
        "num_users = ratings['userId'].max() + 1\n",
        "num_items = ratings['movieId'].max() + 1\n",
        "embedding_dim = 50\n"
      ],
      "metadata": {
        "id": "CZ-R1vZc4nAn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the Recommendation Model"
      ],
      "metadata": {
        "id": "lwWBP_Kx4pqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RecommendationModel(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_dim):\n",
        "        super(RecommendationModel, self).__init__()\n",
        "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
        "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
        "\n",
        "    def forward(self, user, item):\n",
        "        user_embedded = self.user_embedding(user)\n",
        "        item_embedded = self.item_embedding(item)\n",
        "        return (user_embedded * item_embedded).sum(1)\n",
        "\n",
        "model = RecommendationModel(num_users, num_items, embedding_dim)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n"
      ],
      "metadata": {
        "id": "oBifThZO4qRG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the Model with Progress Bar"
      ],
      "metadata": {
        "id": "-inBWGjB47aD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(model, train_loader, criterion, optimizer, num_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        # Initialize the progress bar\n",
        "        for users, items, ratings in tqdm(train_loader, desc=f'Epoch {epoch+1}', unit='batch'):\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(users, items)\n",
        "            loss = criterion(outputs, ratings)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the loss for this epoch\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        # Print the average loss for this epoch\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        print(f'Epoch {epoch+1}, Average Loss: {avg_loss:.4f}')\n",
        "\n",
        "# Train the model with progress bar\n",
        "train(model, train_loader, criterion, optimizer, num_epochs=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQ_yQYRa47zs",
        "outputId": "d8e81d51-c384-4f0b-b1eb-2f414ba8563b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|█████████▉| 1260/1261 [04:17<00:00,  5.50batch/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the Model"
      ],
      "metadata": {
        "id": "Palb-CWg5BLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for users, items, ratings in test_loader:\n",
        "            outputs = model(users, items)\n",
        "            loss = criterion(outputs, ratings)\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(test_loader)\n",
        "\n",
        "test_loss = evaluate(model, test_loader)\n",
        "print(f'Test Loss: {test_loss}')\n"
      ],
      "metadata": {
        "id": "RhwuWGMB5Cn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Movie Titles"
      ],
      "metadata": {
        "id": "9IepZRDh5GMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load movie titles dataset\n",
        "movies = pd.read_csv('ml-latest-small/movies.csv')\n",
        "movie_titles = movies['title'].tolist()\n"
      ],
      "metadata": {
        "id": "wdRDOxgv5HXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Recommendation Function and Test"
      ],
      "metadata": {
        "id": "zzC6REru5KIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_movie_recommendations(user_id, model, movie_titles, num_recommendations=5):\n",
        "    user_id_tensor = torch.tensor([user_id])\n",
        "\n",
        "    # Get embeddings for the user and all movies\n",
        "    with torch.no_grad():\n",
        "        user_embedding = model.user_embedding(user_id_tensor)\n",
        "        all_movie_ids = torch.arange(len(movie_titles))\n",
        "        movie_embeddings = model.item_embedding(all_movie_ids)\n",
        "\n",
        "        # Calculate predicted ratings\n",
        "        predicted_ratings = (user_embedding @ movie_embeddings.t()).squeeze()\n",
        "\n",
        "        # Get the top N movie indices\n",
        "        top_movie_indices = torch.topk(predicted_ratings, num_recommendations).indices.tolist()\n",
        "\n",
        "        # Get the corresponding movie titles\n",
        "        recommended_movies = [movie_titles[i] for i in top_movie_indices]\n",
        "\n",
        "    return recommended_movies\n",
        "\n",
        "# Get recommendations for a sample user (e.g., user_id=1)\n",
        "sample_user_id = 1\n",
        "recommended_movies = get_movie_recommendations(sample_user_id, model, movie_titles, num_recommendations=5)\n",
        "\n",
        "# Display the recommended movies\n",
        "print(f\"Recommended movies for user {sample_user_id}:\")\n",
        "for i, movie_title in enumerate(recommended_movies, 1):\n",
        "    print(f\"{i}. {movie_title}\")\n"
      ],
      "metadata": {
        "id": "Hhs1Bw8p5MyP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}